1.Amazon SWF provides useful guarantees around task assignments. It ensures that a task is never duplicated and is assigned only once. 
Thus, even though you may have multiple workers for a particular activity type (or a number of instances of a decider), Amazon SWF will give a specific task to only one worker (or one decider instance).
Additionally, Amazon SWF keeps at most one decision task outstanding at a time for workflow execution. Thus, you can run multiple decider instances without worrying about two instances operating on the same execution simultaneously. 
These facilities enable you to coordinate your workflow without worrying about duplicate, lost, or conflicting tasks.


2.Predictive scaling uses machine learning to predict capacity requirements based on historical data from CloudWatch. 
The machine learning algorithm consumes the available historical data and calculates capacity that best fits the historical load pattern, and then continuously learns based on new data to make future forecasts more accurate.
In general, if you have regular patterns of traffic increases and applications that take a long time to initialize, you should consider using predictive scaling. 
Predictive scaling can help you scale faster by launching capacity in advance of forecasted load, compared to using only dynamic scaling, which is reactive in nature. 
Predictive scaling can also potentially save you money on your EC2 bill by helping you avoid the need to overprovision capacity. 
You also don't have to spend time reviewing your application's load patterns and trying to schedule the right amount of capacity using scheduled scaling.

3.SAML, which stands for Security Assertion Markup Language, is a specific protocol used for implementing Single Sign-On (SSO).

4.There are two AWS services for issuing and deploying X.509 certificates. Choose the one that best fits your needs.
Considerations include whether you need public- or private-facing certificates, customized certificates, certificates you want to deploy into other AWS services, or automated certificate management and renewal.

In the context of web security, X.509 certificates play a crucial role in SSL/TLS (Secure Sockets Layer/Transport Layer Security) protocols, where they are used to secure the communication between web browsers and servers. A server's X.509 certificate is presented to the client to establish a secure connection.

ACM public certificates are used to secure public-facing services accessible over the internet, while ACM private certificates are used to secure internal resources and services within an AWS VPC or a private network. 


5.You can configure Amazon Redshift to copy snapshots for a cluster to another region. To configure cross-region snapshot copy, you need to enable this copy feature for each cluster and configure where to copy snapshots and how long to keep copied automated snapshots in the destination region. 
When a cross-region copy is enabled for a cluster, all new manual and automatic snapshots are copied to the specified region.


6.CORS will only allow objects from one domain (travel.cebu.com) to be loaded and accessible to a different domain (palawan.com). It won't necessarily expose objects for public access all over the internet.
Amazon S3 defaults to private access, but allows resource owners to set access policies, including public access, via resource-based and user-based policies. Public access is granted for specific use cases, like hosting websites.

7.You can provision a certain number of IOPS for an io1 volume, ranging from 100 to 64,000 IOPS, depending on the volume's size.
The maximum ratio of provisioned IOPS to the volume's size (in GiB) is 50:1.
For volumes larger than 1,280 GiB, you can provision up to the maximum of 64,000 IOPS.
So, for example, if you have a 10 GiB volume, you can provision up to 500 IOPS (10 GiB x 50). If you have a 640 GiB volume, you can provision up to the maximum of 32,000 IOPS (640 GiB x 50).


8.A global secondary index can only be created in the region where its parent table resides.
You can also use the Well-Architected Tool to automatically monitor the status of your workloads across your AWS account, conduct architectural reviews and check for AWS best practices.
This tool is based on the AWS Well-Architected Framework, which was developed to help cloud architects build secure, high-performing, resilient, and efficient application infrastructures. The Framework has been used in tens of thousands of workload reviews by AWS solutions architects, and it provides a consistent approach for evaluating your cloud architecture and implementing designs that will scale with your application needs over time.


9.AWS Health offers real-time visibility into the performance and availability of AWS services and resources. It allows users to stay informed about how service and resource changes may impact their AWS applications. You can use AWS Health events to monitor ongoing events and prepare for planned activities. Amazon EventBridge can be employed to detect and respond to these events by creating rules that trigger specific actions, such as email notifications for scheduled updates of AWS resources in your account. The "Your account events" page provides a comprehensive view of events specific to your account, including open, recent, and scheduled changes, notifications, and a 90-day event log.


10.AWS VPN CloudHub is only for VPNs and not for VPCs. It is also not capable of managing hundreds of VPCs with multiple VPN connections to their data centers that span multiple AWS Regions.

11.you cannot modify the built-in key rotation feature manually in SSE-S3. These keys are managed by AWS, and not you. 
 Amazon S3's Server-Side Encryption (SSE) with S3 Managed Keys (SSE-S3) automatically rotates keys approximately every 90 days. 


12.AWS App Mesh simply focuses on providing service mesh capabilities such as observability and traffic control but does not automatically scales in and out. Amazon CloudWatch Application Insights only reduces the time it takes to set up monitoring for your applications by scanning your application resources. It provides a customizable list of recommended metrics and logs while providing the necessary visibility into your application resources. This CloudWatch feature is not capable of autoscaling your EKS cluster.

Autoscaling is a function that automatically scales your resources up or down to meet changing demands. This is a major Kubernetes function that would otherwise require extensive human resources to perform manually.

Amazon EKS supports two autoscaling solutions:
Karpenter is a flexible, high-performance Kubernetes cluster autoscaler that launches appropriately sized compute resources, like Amazon EC2 instances, in response to changing application load. It integrates with AWS to provision compute resources that precisely match workload requirements.

Cluster Autoscaler, on the other hand, automatically adjusts the number of nodes in a cluster based on pod failures or rescheduling. It utilizes Auto Scaling groups for managing the cluster's node capacity.

The Kubernetes Horizontal Pod Autoscaler (HPA) automatically scales the number of Pods based on CPU utilization, allowing applications to scale in or out to meet demand. It is a standard API resource in Kubernetes that requires a metrics source like the Kubernetes metrics server to be installed on the Amazon EKS cluster. The HPA does not need additional deployment or installation on the cluster to start scaling applications.


13.Enable the Requester Pays feature on the Amazon S3 bucket to lower data transfer costs and disable anonymous access


14.Although the Amazon Rekognition service can technically detect text in images and videos, this service is still not suitable for extracting text from PDF reports. A more suitable solution is to use Amazon Textract.

15.AWS Application Migration Service (AWS MGN) is the primary migration service recommended for lift-and-shift migrations to AWS. AWS encourages customers who are currently using AWS Elastic Disaster Recovery to switch to AWS MGN for future migrations. AWS MGN enables organizations to move applications to AWS without having to make any changes to the applications, their architecture, or the migrated servers.

AWS Application Migration Service minimizes time-intensive, error-prone manual processes by automatically converting your source servers from physical, virtual machines, and cloud infrastructure to run natively on AWS.
The service simplifies your migration by enabling you to use the same automated process for a wide range of applications. By launching non-disruptive tests before migrating, you can be confident that your most critical applications such as SAP, Oracle, and SQL Server, will work seamlessly on AWS.
Implementation begins by installing the AWS Replication Agent on your source servers. When you launch Test or Cutover instances, AWS Application Migration Service automatically converts your source servers to boot and runs natively on AWS.

16. S3 Select

Amazon S3 Select is designed to help analyze and process data within an object in Amazon S3 buckets, faster and cheaper. It works by providing the ability to retrieve a subset of data from an object in Amazon S3 using simple SQL expressions. Your applications no longer have to use compute resources to scan and filter the data from an object, potentially increasing query performance by up to 400%, and reducing query costs as much as 80%. You simply change your application to use SELECT instead of GET to take advantage of S3 Select.

 Amazon Athena

Amazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL expressions. Athena is serverless, so there is no infrastructure to manage, and you pay only for the queries you run. Athena is easy to use. Simply point to your data in Amazon S3, define the schema, and start querying using standard SQL expressions. Most results are delivered within seconds. With Athena, there’s no need for complex ETL jobs to prepare your data for analysis. This makes it easy for anyone with SQL skills to quickly analyze large-scale datasets.

 Amazon Redshift Spectrum

Amazon Redshift also includes Redshift Spectrum, allowing you to directly run SQL queries against exabytes of unstructured data in Amazon S3. No loading or transformation is required, and you can use open data formats, including Avro, CSV, Grok, ORC, Parquet, RCFile, RegexSerDe, SequenceFile, TextFile, and TSV. Redshift Spectrum automatically scales query compute capacity based on the data being retrieved, so queries against Amazon S3 run fast, regardless of data set size.


17.ACM lets you import third-party certificates from the ACM console, as well as programmatically. If ACM is not available in your region, use AWS CLI to upload your third-party certificate to the IAM certificate store.


18.Flow Logs are used in VPC and not on specific EC2 instance

19. taking a snapshot allows you to capture the current state of the database, including all data and configurations. By terminating the database, you can avoid incurring costs during the idle period between tests. You can simply restore the database from the snapshot when you need to run the tests again. This approach helps minimize costs by only paying for the database instance during the actual testing periods.
