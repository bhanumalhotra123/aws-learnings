Test4

1.Amazon SageMaker helps data scientists and developers to prepare, build, train, and deploy high-quality machine learning (ML) models quickly by bringing together a broad set of capabilities purpose-built for ML.  

2.many organizations are orchestrating their containerized services with Amazon Elastic Container Service (Amazon ECS) or Amazon Elastic Kubernetes Service (Amazon EKS), while hosting their containers on Amazon EC2 or AWS Fargate. Then, they can add scalability and high availability with Service Auto Scaling (in Amazon ECS) or Horizontal Pod Auto Scaler (in Amazon EKS), and they expose the services through load balancers.  
  
When you use Amazon ECS as an orchestrator (with EC2 or Fargate launch type), you also have the option to expose your services with Amazon API Gateway and AWS Cloud Map instead of a load balancer. AWS Cloud Map is used for service discovery: no matter how Amazon ECS tasks scale, AWS Cloud Map service names would point to the right set of Amazon ECS tasks. Then, API Gateway HTTP APIs can be used to define API routes and point them to the corresponding AWS Cloud Map services.  

3. Alias records let you route traffic to selected AWS resources, such as CloudFront distributions and Amazon S3 buckets. They also let you route traffic from one record in a hosted zone to another record. Unlike a CNAME record, you can create an alias record at the top node of a DNS namespace, also known as the zone apex. For example, if you register the DNS name example.com, the zone apex is example.com. You can't create a CNAME record for example.com, but you can create an alias record for example.com that routes traffic to www.example.com.

4.Simple DNS records, such as A and CNAME records, do not support health checks directly. Health checks are typically associated with other types of DNS records, like the "Alias" records (e.g., ALIAS and CAA records) or weighted routing records. These records allow you to configure routing policies based on the health of the underlying resources.  
If you need to perform health checks and route traffic based on the health status of your resources, you may want to consider using Alias records (which can point to AWS resources like ELB or S3 buckets) or weighted routing policies in combination with health checks.  

5. TTL is still in effect so you have to wait until it expires for the new request to perform another DNS query and get the value for the new Load Balancer.  

6.A DynamoDB stream is an ordered flow of information about changes to items in a DynamoDB table. When you enable a stream on a table, DynamoDB captures information about every modification to data items in the table. Whenever an application creates, updates, or deletes items in the table, DynamoDB Streams writes a stream record with the primary key attributes of the items that were modified. A stream record contains information about a data modification to a single item in a DynamoDB table.  
 It can be chained with a Lambda function that will be triggered to react to these changes.  

7.Types of storage gateways:   
File Gateway: AWS File Gateway enables seamless access to Amazon S3 objects as files, making it suitable for file-based storage, backup, and archive use cases.  
Volume Gateway: AWS Volume Gateway offers block-based storage for applications using iSCSI, with two modes: Cached Volumes for primary data storage and Stored Volumes for full data snapshots and backups.    
Tape Gateway: AWS Tape Gateway emulates a virtual tape library (VTL), allowing on-premises applications to archive data to Amazon S3 and Amazon Glacier as if they were using physical tape backups.  

AWS DataSync supports only NFS and SMB file types  
  
8.Field-level encryption allows you to enable your users to securely upload sensitive information to your web servers. The sensitive information provided by your users is encrypted at the edge, close to the user, and remains encrypted throughout your entire application stack. This encryption ensures that only applications that need the data—and have the credentials to decrypt it—are able to do so.
  
To use field-level encryption, when you configure your CloudFront distribution, specify the set of fields in POST requests that you want to be encrypted, and the public key to use to encrypt them. You can encrypt up to 10 data fields in a request. (You can’t encrypt all of the data in a request with field-level encryption; you must specify individual fields to encrypt.)  

CloudFront can only route to multiple origins based on content type and not on the basis of the price class.  
  Use an origin group with primary and secondary origins to configure CloudFront for high availability and failover.  

9.AWS Snowcone: Snowcone is the smallest and most portable device in the Snow Family. It is designed for remote, edge, or disconnected environments where you need to collect and transfer data. It's small, lightweight, and can fit in a backpack.  
AWS Snowball: Snowball is a larger data transfer device with multiple options, including Snowball Edge and Snowball. It's suitable for larger data transfer jobs and can be used in situations where you need to transfer data from on-premises data centers to AWS.  

AWS Snowball Edge: Snowball Edge includes more storage and compute capabilities than Snowball. It's designed for data migration, edge computing, and running AWS Lambda functions in edge locations. Snowball Edge comes in two models: Storage Optimized and Compute Optimized.
  
AWS Snowmobile: Snowmobile is a massive, rugged shipping container-sized device designed for transferring exabytes of data to AWS. It's used for very large-scale data center migrations.

10.SSL/TLS handshake process with each step attributed to the client and server in the correct sequence:

Client:  
Initiates the handshake by sending a "ClientHello" message.  
Server:  
2. Responds with a "ServerHello" message, selecting the appropriate cipher suite.  
Server:  
3. Sends its SSL certificate to the client.   
Client:  
4. Validates the server's certificate, ensuring it's from a trusted source and matches the intended domain.    
Client:  
5. Generates a session key, encrypts it with the server's public key, and sends it to the server.  
Server:  
6. Decrypts the session key using its private key.    
Both Client and Server:  
7. Use the shared session key for encrypting and decrypting data transmitted between them, ensuring secure communication.  
  
Use SSL certificates with SNI: It allows you to host multiple secured applications with different certificates behind one load balancer, automatically selecting the right certificate based on the requested domain.  
Use a wildcard SSL certificate: It secures multiple subdomains under one domain using a single certificate, simplifying certificate management.  
Use an HTTP to HTTPS redirect: It enforces secure connections by automatically redirecting HTTP traffic to HTTPS but doesn't create multiple secure endpoints for different URLs.  
Change the ELB SSL Security Policy: It configures the security protocols and ciphers for SSL/TLS connections on an Elastic Load Balancer but doesn't inherently provide multiple secure endpoints for different URLs or domains.

8.By default, Lambda functions always operate from an AWS-owned VPC and hence have access to any public internet address or public AWS APIs. Once a Lambda function is VPC-enabled, it will need a route through a NAT gateway in a public subnet to access public resources   

Since Lambda functions can scale extremely quickly, its a good idea to deploy a CloudWatch Alarm that notifies your team when function metrics such as ConcurrentExecutions or Invocations exceeds the expected threshold  
  
You can configure your Lambda function to pull in additional code and content in the form of layers. A layer is a ZIP archive that contains libraries, a custom runtime, or other dependencies. With layers, you can use libraries in your function without needing to include them in your deployment package. Layers let you keep your deployment package small, which makes development easier. A function can use up to 5 layers at a time.
  
You can create layers, or use layers published by AWS and other AWS customers. Layers support resource-based policies for granting layer usage permissions to specific AWS accounts, AWS Organizations, or all accounts. The total unzipped size of the function and all layers can't exceed the unzipped deployment package size limit of 250 MB.  

Overprovisioning function timeout often results in Lambda functions running longer than expected and unexpected costs.  
You can now package and deploy Lambda functions as container images. All the dependencies are also packaged into the single Lambda deployment package.  

9.Use AWS Cost Explorer Resource Optimization to get a report of EC2 instances that are either idle or have low utilization and use AWS Compute Optimizer to look at instance type recommendations  
 Amazon S3 analytics feature observes data access patterns to help you determine when to transition less frequently accessed STANDARD storage to the STANDARD_IA (IA, for infrequent access) storage class. Storage class analysis does not give recommendations for transitions to the ONEZONE_IA or S3 Glacier storage classes  

AWS Trusted Advisor checks for Amazon EC2 Reserved Instances that are scheduled to expire within the next 30 days or have expired in the preceding 30 days. Reserved Instances do not renew automatically; you can continue using an EC2 instance covered by the reservation without interruption, but you will be charged On-Demand rates. Trusted advisor does not have a feature to auto-renew Reserved Instances.  

Compute Optimizer helps you choose the optimal Amazon EC2 instance types, including those that are part of an Amazon EC2 Auto Scaling group, based on your utilization data. It does not recommend instance purchase options.  

10.Set up a DynamoDB table in the on-demand capacity mode (Correct):
  
Choose on-demand capacity mode when you have unpredictable or bursty workloads, or if you prefer paying only for what you use.
DynamoDB automatically allocates capacity as needed without the concept of provisioned capacity.
Ideal for quickly spiking traffic, unpredictable workloads, and when underprovisioned capacity would impact user experience.
Suitable for moving to a NoOps or serverless environment where capacity is managed automatically.
Set up a DynamoDB table in the provisioned capacity mode with auto-scaling enabled (Incorrect):
  
This is not the right choice for unpredictable workloads.
Provisioned capacity mode is designed for scenarios where you have predictable application traffic.
Auto-scaling can help adjust capacity based on traffic changes, but it's more suited for applications with consistent or gradually increasing traffic.
Set up a DynamoDB table with a global secondary index (Incorrect):
  
A global secondary index (GSI) is an additional index that you create on a DynamoDB table.
GSIs are useful for querying data in different ways, but they don't affect the capacity mode (on-demand or provisioned) of the table.
GSIs are not designed to handle unpredictable or bursty traffic patterns; their purpose is to provide more querying flexibility.
Set up a DynamoDB global table in the provisioned capacity mode (Incorrect):
  
DynamoDB global tables are used to replicate data across multiple AWS Regions for high availability and disaster recovery.
Provisioned capacity mode in a global table means you specify a fixed amount of capacity for each region, which is not suitable for unpredictable workloads.
Global tables are primarily used to provide fast, local read and write performance for global applications but don't directly address unpredictable traffic.
  

